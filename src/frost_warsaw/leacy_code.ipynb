{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c63f679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import PillowWriter, FuncAnimation\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import warnings\n",
    "from shapely.geometry import Point, LineString\n",
    "from loguru import logger\n",
    "from IPython.display import Image\n",
    "from matplotlib.collections import LineCollection\n",
    "from scipy.interpolate import splprep, splev\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"osmnx\")\n",
    "pd.set_option(\"display.float_format\", \"{:.6f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7394d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stops data is taken direcly from ZTM website and it\"s processed inside \"get_stops_data.py\"\n",
    "# It has no use for now, because I decited to use different routes source\n",
    "\n",
    "stops_data = pd.read_csv(f\"{data_parent_directory}/stops.csv\", dtype={\n",
    "    \"stop_ordinal_number\": str,\n",
    "    \"street_id\": str,\n",
    "    \"type_id\": str,\n",
    "    \"stop_id\": str,\n",
    "})\n",
    "\n",
    "stops_data = gpd.GeoDataFrame(stops_data, geometry=gpd.points_from_xy(stops_data[\"lon\"], stops_data[\"lat\"]))\n",
    "stops_data = stops_data[[\"line\", \"stop_ordinal_number\", \"complex_id\", \"type_name\", \"geometry\"]]\n",
    "stops_data = stops_data.drop_duplicates()\n",
    "stops_data = stops_data.set_crs(epsg=4326)\n",
    "stops_data = stops_data.to_crs(epsg=2180)\n",
    "\n",
    "stops_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f38913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data is taken from the \"https://mkuran.pl/gtfs/\" website and it links information about line (route_id)\n",
    "# brigade and shape_id\n",
    "\n",
    "trips = pd.read_csv(f\"{data_parent_directory}/routes_detailed/trips.txt\", dtype={\"brigade\": str})\n",
    "trips = trips[[\"route_id\", \"shape_id\", \"brigade\"]]\n",
    "trips = trips.drop_duplicates()\n",
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe6fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data is taken from the \"https://mkuran.pl/gtfs/\" website and it contains sequences of the route of any shape_id\n",
    "# shape_id is taken from the previos table\n",
    "\n",
    "shapes = pd.read_csv(f\"{data_parent_directory}/routes_detailed/shapes.txt\")\n",
    "shapes = shapes[shapes[\"shape_id\"].isin(trips[\"shape_id\"].unique())]\n",
    "shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc67752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I take points and make linestring out of them. Next I merge it with the information about line and brigade\n",
    "# also here I change EPSG to 2180\n",
    "\n",
    "def make_linestring(df):\n",
    "    df = df.sort_values(\"shape_pt_sequence\")\n",
    "    points = list(zip(df[\"shape_pt_lon\"], df[\"shape_pt_lat\"]))\n",
    "    return LineString(points)\n",
    "\n",
    "lines = shapes.groupby(\"shape_id\").apply(make_linestring).reset_index(name=\"geometry\")\n",
    "\n",
    "routes_detailed = gpd.GeoDataFrame(lines, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "routes_detailed = routes_detailed.merge(\n",
    "    trips,\n",
    "    on=[\"shape_id\"],\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\",\n",
    ")\n",
    "\n",
    "routes_detailed = routes_detailed.to_crs(epsg=\"2180\")\n",
    "routes_detailed = routes_detailed.rename(columns={\"route_id\": \"line\"})\n",
    "\n",
    "mask_duplicates = routes_detailed[[\"line\", \"brigade\"]].duplicated()\n",
    "print_removed(routes_detailed, mask_duplicates)\n",
    "\n",
    "routes_detailed = routes_detailed[~mask_duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec008d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I merge routes details with gps data:\n",
    "# - merge by \"line\" and \"brigade\" first\n",
    "# - if there are some data missing I merge data again, but on \"line\" only - it\"s better to have a route than not\n",
    "#   and there is a high probability that it will match\n",
    "\n",
    "# NOT USED FOR NOW\n",
    "\n",
    "gps_data_routes = gps_data_processed.copy()\n",
    "gps_data_routes = gps_data_routes.merge(\n",
    "    routes_detailed.rename(columns={\"geometry\": \"route_shape\"}),\n",
    "    on=[\"line\", \"brigade\"],\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\",\n",
    ")\n",
    "\n",
    "gps_data_routes = gps_data_routes.merge(\n",
    "    routes_detailed.drop(columns=[\"brigade\"]).rename(columns={\"geometry\": \"route_shape\"}).drop_duplicates(subset=[\"line\"]),\n",
    "    on=[\"line\"],\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\",\n",
    "    suffixes=(\"\", \"_missing\")\n",
    ")\n",
    "\n",
    "missing_from_first_merge = gps_data_routes[\"shape_id\"].isna() & gps_data_routes[\"shape_id_missing\"].notnull()\n",
    "logger.info(\n",
    "    f\"There are {missing_from_first_merge.sum()} rows that have missing routes after first merege. \"\n",
    "    f\"Here are some details: {gps_data_routes.loc[missing_from_first_merge, [\"line\", \"brigade\"]].drop_duplicates()}\"\n",
    "    )\n",
    "\n",
    "for rep_col in [\"shape_id\", \"route_shape\"]:\n",
    "    gps_data_routes[rep_col] = gps_data_routes[rep_col].fillna(gps_data_routes[f\"{rep_col}_missing\"])\n",
    "    gps_data_routes = gps_data_routes.drop(columns=[f\"{rep_col}_missing\"])\n",
    "    \n",
    "gps_data_routes"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
